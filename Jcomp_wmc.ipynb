{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e38bbcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,  Model\n",
    "from keras.layers import Convolution2D,Input,BatchNormalization,Conv2D,Activation,Lambda,Subtract,Conv2DTranspose, PReLU\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import  Reshape,Dense,Flatten\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam\n",
    "from scipy.io import loadmat\n",
    "import keras.backend as K\n",
    "# from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import interpolate\n",
    "#from scipy.misc import imresize\n",
    "\n",
    "\n",
    "def psnr(target, ref):\n",
    "    # assume RGB image\n",
    "    target_data = np.array(target, dtype=float)\n",
    "    ref_data = np.array(ref, dtype=float)\n",
    "\n",
    "    diff = ref_data - target_data\n",
    "    diff = diff.flatten('C')\n",
    "\n",
    "    rmse = math.sqrt(np.mean(diff ** 2.))\n",
    "\n",
    "    return 20 * math.log10(255. / rmse)\n",
    "\n",
    "def interpolation(noisy , SNR , Number_of_pilot , interp):\n",
    "    noisy_image = np.zeros((40000,72,14,2))\n",
    "\n",
    "    noisy_image[:,:,:,0] = np.real(noisy)\n",
    "    noisy_image[:,:,:,1] = np.imag(noisy)\n",
    "\n",
    "\n",
    "    if (Number_of_pilot == 48):\n",
    "        idx = [14*i for i in range(1, 72,6)]+[4+14*(i) for i in range(4, 72,6)]+[7+14*(i) for i in range(1, 72,6)]+[11+14*(i) for i in range(4, 72,6)]\n",
    "    elif (Number_of_pilot == 16):\n",
    "        idx= [4+14*(i) for i in range(1, 72,9)]+[9+14*(i) for i in range(4, 72,9)]\n",
    "    elif (Number_of_pilot == 24):\n",
    "        idx = [14*i for i in range(1,72,9)]+ [6+14*i for i in range(4,72,9)]+ [11+14*i for i in range(1,72,9)]\n",
    "    elif (Number_of_pilot == 8):\n",
    "      idx = [4+14*(i) for  i in range(5,72,18)]+[9+14*(i) for i in range(8,72,18)]\n",
    "    elif (Number_of_pilot == 36):\n",
    "      idx = [14*(i) for  i in range(1,72,6)]+[6+14*(i) for i in range(4,72,6)] + [11+14*i for i in range(1,72,6)]\n",
    "\n",
    "\n",
    "\n",
    "    r = [x//14 for x in idx]\n",
    "    c = [x%14 for x in idx]\n",
    "\n",
    "\n",
    "\n",
    "    interp_noisy = np.zeros((40000,72,14,2))\n",
    "\n",
    "    for i in range(len(noisy)):\n",
    "        z = [noisy_image[i,j,k,0] for j,k in zip(r,c)]\n",
    "        if(interp == 'rbf'):\n",
    "            f = interpolate.Rbf(np.array(r).astype(float), np.array(c).astype(float), z,function='gaussian')\n",
    "            X , Y = np.meshgrid(range(72),range(14))\n",
    "            z_intp = f(X, Y)\n",
    "            interp_noisy[i,:,:,0] = z_intp.T\n",
    "        elif(interp == 'spline'):\n",
    "            tck = interpolate.bisplrep(np.array(r).astype(float), np.array(c).astype(float), z)\n",
    "            z_intp = interpolate.bisplev(range(72),range(14),tck)\n",
    "            interp_noisy[i,:,:,0] = z_intp\n",
    "        z = [noisy_image[i,j,k,1] for j,k in zip(r,c)]\n",
    "        if(interp == 'rbf'):\n",
    "            f = interpolate.Rbf(np.array(r).astype(float), np.array(c).astype(float), z,function='gaussian')\n",
    "            X , Y = np.meshgrid(range(72),range(14))\n",
    "            z_intp = f(X, Y)\n",
    "            interp_noisy[i,:,:,1] = z_intp.T\n",
    "        elif(interp == 'spline'):\n",
    "            tck = interpolate.bisplrep(np.array(r).astype(float), np.array(c).astype(float), z)\n",
    "            z_intp = interpolate.bisplev(range(72),range(14),tck)\n",
    "            interp_noisy[i,:,:,1] = z_intp\n",
    "\n",
    "\n",
    "    interp_noisy = np.concatenate((interp_noisy[:,:,:,0], interp_noisy[:,:,:,1]), axis=0).reshape(80000, 72, 14, 1)\n",
    "   \n",
    "    \n",
    "    return interp_noisy\n",
    "\n",
    "def SRCNN_model():\n",
    "\n",
    "    input_shape = (72,14,1)\n",
    "    x = Input(shape = input_shape)\n",
    "    c1 = Conv2D( 64 , (9 , 9) ,activation = 'relu', kernel_initializer = 'he_normal', padding='same')(x)\n",
    "    c2 = Conv2D( 32 ,(1,1), activation = 'relu', kernel_initializer = 'he_normal', padding='same')(c1)\n",
    "    c3 = Conv2D( 1 , (5,5), kernel_initializer = 'he_normal', padding='same')(c2)\n",
    "    #c4 = Input(shape = input_shape)(c3)\n",
    "    model = Model(inputs = x, outputs = c3)\n",
    "    ##compile\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8) \n",
    "    model.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error']) \n",
    "    return model\n",
    "    \n",
    "def SRCNN_train(train_data ,train_label, val_data , val_label , channel_model, num_pilots , SNR ):\n",
    "    srcnn_model = SRCNN_model()\n",
    "    print(srcnn_model.summary())\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\"SRCNN_check.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                                 save_weights_only=False, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    srcnn_model.fit(train_data, train_label, batch_size=128, validation_data=(val_data, val_label),\n",
    "                    callbacks=callbacks_list, shuffle=True, epochs= 10 , verbose=1)\n",
    "    \n",
    "    #srcnn_model.save_weights(\"drive/codes/my_srcnn/SRCNN_SUI5_weights/SRCNN_48_12.h5\")\n",
    "    srcnn_model.save_weights(\"SRCNN_\" + channel_model +\"_\"+ str(num_pilots) + \"_\"  + str(SNR) + \".h5\")\n",
    "   \n",
    "\n",
    "\n",
    "def SRCNN_predict(input_data , channel_model , num_pilots , SNR):\n",
    "    srcnn_model = SRCNN_model()\n",
    "    srcnn_model.load_weights(\"SRCNN_\" + channel_model +\"_\"+ str(num_pilots) + \"_\"  + str(SNR) + \".h5\")\n",
    "    predicted  = srcnn_model.predict(input_data)\n",
    "    return predicted\n",
    "\n",
    "  \n",
    "def DNCNN_model ():\n",
    "  \n",
    "    inpt = Input(shape=(None,None,1))\n",
    "    # 1st layer, Conv+relu\n",
    "    x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(inpt)\n",
    "    x = Activation('relu')(x)\n",
    "    # 18 layers, Conv+BN+relu\n",
    "    for i in range(18):\n",
    "        x = Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same')(x)\n",
    "        x = BatchNormalization(axis=-1, epsilon=1e-3)(x)\n",
    "        x = Activation('relu')(x)   \n",
    "    # last layer, Conv\n",
    "    x = Conv2D(filters=1, kernel_size=(3,3), strides=(1,1), padding='same')(x)\n",
    "    x = Subtract()([inpt, x])   # input - noise\n",
    "    model = Model(inputs=inpt, outputs=x)\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8) \n",
    "    model.compile(optimizer=adam, loss='mean_squared_error', metrics=['mean_squared_error'])    \n",
    "    return model\n",
    "\n",
    "def DNCNN_train(train_data ,train_label, val_data , val_label, channel_model , num_pilots , SNR ):\n",
    "  \n",
    "  dncnn_model = DNCNN_model()\n",
    "  print(dncnn_model.summary())\n",
    "\n",
    "  checkpoint = ModelCheckpoint(\"DNCNN_check.h5\", monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                               save_weights_only=False, mode='min')\n",
    "  callbacks_list = [checkpoint]\n",
    "\n",
    "  dncnn_model.fit(train_data, train_label, batch_size=128, validation_data=(val_data, val_label),\n",
    "                  callbacks=callbacks_list, shuffle=True, epochs= 5 , verbose=1)\n",
    "  dncnn_model.save_weights(\"DNCNN_\" + channel_model +\"_\"+ str(num_pilots) + \"_\"  + str(SNR) + \".h5\")\n",
    "  \n",
    "  \n",
    "  \n",
    "def DNCNN_predict(input_data, channel_model , num_pilots , SNR):\n",
    "  dncnn_model = DNCNN_model()\n",
    "  dncnn_model.load_weights(\"DNCNN_\" + channel_model +\"_\"+ str(num_pilots) + \"_\"  + str(SNR) + \".h5\")\n",
    "  predicted  = dncnn_model.predict(input_data)\n",
    "  return predicted\n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbaa7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_input = loadmat(\"My_noisy_H_22\", appendmat = True )['My_noisy_H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a517adf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.012686757842631352-0.8107323370829541j)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_input[32][23][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbf5fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd4fa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 72, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(noisy_input)\n",
    "noisy_input.shape\n",
    "#40000 channels \n",
    "#72 frequency subcarriers\n",
    "#14 time slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42dcbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect = loadmat(\"Perfect_H_40000\", appendmat=True)['My_perfect_H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4d852c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 72, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae38cf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-7fc29c541147>:7: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  img = Image.fromarray(np.uint8(mat * 255),'L')\n"
     ]
    }
   ],
   "source": [
    "# reshape to 2d\n",
    "#mat = np.reshape(perfect[1],(256,256))\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "mat = noisy_input[5600]\n",
    "# Creates PIL image\n",
    "img = Image.fromarray(np.uint8(mat * 255),'L')\n",
    "#img = Image.fromarray(np.uint8(m , 'L')\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aff80bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 72, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(perfect)\n",
    "perfect.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc5191e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal to noise ratio\n",
    "def psnr(target, ref):\n",
    "    # assume RGB image\n",
    "    target_data = np.array(target, dtype=float)\n",
    "    ref_data = np.array(ref, dtype=float)\n",
    "\n",
    "    diff = ref_data - target_data\n",
    "    diff = diff.flatten('C')\n",
    "\n",
    "    rmse = math.sqrt(np.mean(diff ** 2.))\n",
    "\n",
    "    return 20 * math.log10(255. / rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791ea64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(noisy, SNR, Number_of_pilot, interp):\n",
    "    noisy_image = np.zeros((40000,72,14,2))\n",
    "\n",
    "    noisy_image[:,:,:,0] = np.real(noisy)\n",
    "    noisy_image[:,:,:,1] = np.imag(noisy)\n",
    "\n",
    "\n",
    "    if (Number_of_pilot == 48):\n",
    "        idx = [14*i for i in range(1, 72,6)]+[4+14*(i) for i in range(4, 72,6)]+[7+14*(i) for i in range(1, 72,6)]+[11+14*(i) for i in range(4, 72,6)]\n",
    "    elif (Number_of_pilot == 16):\n",
    "        idx= [4+14*(i) for i in range(1, 72,9)]+[9+14*(i) for i in range(4, 72,9)]\n",
    "    elif (Number_of_pilot == 24):\n",
    "        idx = [14*i for i in range(1,72,9)]+ [6+14*i for i in range(4,72,9)]+ [11+14*i for i in range(1,72,9)]\n",
    "    elif (Number_of_pilot == 8):\n",
    "        idx = [4+14*(i) for  i in range(5,72,18)]+[9+14*(i) for i in range(8,72,18)]\n",
    "    elif (Number_of_pilot == 36):\n",
    "        idx = [14*(i) for  i in range(1,72,6)]+[6+14*(i) for i in range(4,72,6)] + [11+14*i for i in range(1,72,6)]\n",
    "\n",
    "\n",
    "\n",
    "    r = [x//14 for x in idx]\n",
    "    c = [x%14 for x in idx]\n",
    "\n",
    "\n",
    "\n",
    "    interp_noisy = np.zeros((40000,72,14,2))\n",
    "\n",
    "    for i in range(len(noisy)):\n",
    "        z = [noisy_image[i,j,k,0] for j,k in zip(r,c)]\n",
    "        if(interp == 'rbf'):\n",
    "            f = interpolate.Rbf(np.array(r).astype(float), np.array(c).astype(float), z,function='gaussian')\n",
    "            X , Y = np.meshgrid(range(72),range(14))\n",
    "            z_intp = f(X, Y)\n",
    "            interp_noisy[i,:,:,0] = z_intp.T\n",
    "        elif(interp == 'spline'):\n",
    "            tck = interpolate.bisplrep(np.array(r).astype(float), np.array(c).astype(float), z)\n",
    "            z_intp = interpolate.bisplev(range(72),range(14),tck)\n",
    "            interp_noisy[i,:,:,0] = z_intp\n",
    "        z = [noisy_image[i,j,k,1] for j,k in zip(r,c)]\n",
    "        if(interp == 'rbf'):\n",
    "            f = interpolate.Rbf(np.array(r).astype(float), np.array(c).astype(float), z,function='gaussian')\n",
    "            X , Y = np.meshgrid(range(72),range(14))\n",
    "            z_intp = f(X, Y)\n",
    "            interp_noisy[i,:,:,1] = z_intp.T\n",
    "        elif(interp == 'spline'):\n",
    "            tck = interpolate.bisplrep(np.array(r).astype(float), np.array(c).astype(float), z)\n",
    "            z_intp = interpolate.bisplev(range(72),range(14),tck)\n",
    "            interp_noisy[i,:,:,1] = z_intp\n",
    "\n",
    "\n",
    "    interp_noisy = np.concatenate((interp_noisy[:,:,:,0], interp_noisy[:,:,:,1]), axis=0).reshape(80000, 72, 14, 1)\n",
    "   \n",
    "    \n",
    "    return interp_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62a30a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 72, 14, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 72, 14, 64)        5248      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 14, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 14, 1)         801       \n",
      "=================================================================\n",
      "Total params: 8,129\n",
      "Trainable params: 8,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0557 - mean_squared_error: 0.0557\n",
      "Epoch 00001: val_loss improved from inf to 0.00870, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 61s 853ms/step - loss: 0.0557 - mean_squared_error: 0.0557 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0064 - mean_squared_error: 0.0064\n",
      "Epoch 00002: val_loss improved from 0.00870 to 0.00479, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 67s 938ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0048 - val_mean_squared_error: 0.0048\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0042 - mean_squared_error: 0.0042\n",
      "Epoch 00003: val_loss improved from 0.00479 to 0.00378, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 59s 827ms/step - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 00004: val_loss improved from 0.00378 to 0.00320, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 59s 828ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 00005: val_loss improved from 0.00320 to 0.00289, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 58s 822ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 00006: val_loss improved from 0.00289 to 0.00264, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 59s 828ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 00007: val_loss did not improve from 0.00264\n",
      "71/71 [==============================] - 58s 822ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 00008: val_loss improved from 0.00264 to 0.00236, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 59s 832ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 00009: val_loss did not improve from 0.00236\n",
      "71/71 [==============================] - 58s 824ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 00010: val_loss improved from 0.00236 to 0.00224, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 62s 871ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 00011: val_loss improved from 0.00224 to 0.00219, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 63s 893ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 00012: val_loss improved from 0.00219 to 0.00213, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 63s 884ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 00013: val_loss improved from 0.00213 to 0.00205, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 63s 886ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 00014: val_loss did not improve from 0.00205\n",
      "71/71 [==============================] - 63s 883ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 00015: val_loss improved from 0.00205 to 0.00203, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 63s 883ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 00016: val_loss improved from 0.00203 to 0.00194, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 63s 884ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 00017: val_loss did not improve from 0.00194\n",
      "71/71 [==============================] - 63s 880ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 00018: val_loss did not improve from 0.00194\n",
      "71/71 [==============================] - 63s 884ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 00019: val_loss improved from 0.00194 to 0.00190, saving model to SRCNN_check.h5\n",
      "71/71 [==============================] - 63s 888ms/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 00020: val_loss did not improve from 0.00190\n",
      "71/71 [==============================] - 63s 881ms/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 640         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, None, 6 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 6 36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 6 256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 6 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 6 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 6 256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 6 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 6 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 6 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 6 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 6 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 6 36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 6 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 6 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 6 256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 6 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 6 36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 6 256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 6 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 6 256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 6 36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 6 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 6 36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 6 36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 6 256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 6 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 1 577         activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, None, None, 1 0           input_4[0][0]                    \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 670,529\n",
      "Trainable params: 668,225\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - ETA: 0s - loss: 0.0852 - mean_squared_error: 0.0852\n",
      "Epoch 00001: val_loss improved from inf to 0.00963, saving model to DNCNN_check.h5\n",
      "71/71 [==============================] - 1260s 18s/step - loss: 0.0852 - mean_squared_error: 0.0852 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0045 - mean_squared_error: 0.0045\n",
      "Epoch 00002: val_loss improved from 0.00963 to 0.00843, saving model to DNCNN_check.h5\n",
      "71/71 [==============================] - 1276s 18s/step - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0037 - mean_squared_error: 0.0037\n",
      "Epoch 00003: val_loss improved from 0.00843 to 0.00709, saving model to DNCNN_check.h5\n",
      "71/71 [==============================] - 1252s 18s/step - loss: 0.0037 - mean_squared_error: 0.0037 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 00004: val_loss improved from 0.00709 to 0.00545, saving model to DNCNN_check.h5\n",
      "71/71 [==============================] - 1250s 18s/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0055 - val_mean_squared_error: 0.0055\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 00005: val_loss improved from 0.00545 to 0.00400, saving model to DNCNN_check.h5\n",
      "71/71 [==============================] - 1257s 18s/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 00006: val_loss improved from 0.00400 to 0.00312, saving model to DNCNN_check.h5\n",
      "71/71 [==============================] - 1255s 18s/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 00007: val_loss improved from 0.00312 to 0.00249, saving model to DNCNN_check.h5\n",
      "71/71 [==============================] - 1254s 18s/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0020 - mean_squared_error: 0.0020\n",
      "Epoch 00008: val_loss improved from 0.00249 to 0.00240, saving model to DNCNN_check.h5\n",
      "71/71 [==============================] - 1252s 18s/step - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 00009: val_loss improved from 0.00240 to 0.00211, saving model to DNCNN_check.h5\n",
      "71/71 [==============================] - 1254s 18s/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0018\n",
      "Epoch 00010: val_loss improved from 0.00211 to 0.00191, saving model to DNCNN_check.h5\n",
      "71/71 [==============================] - 1255s 18s/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n"
     ]
    }
   ],
   "source": [
    "###### import numpy as np\n",
    "import numpy\n",
    "import math\n",
    "#from models import interpolation , SRCNN_train , SRCNN_model, SRCNN_predict , DNCNN_train , DNCNN_model , DNCNN_predict\n",
    "#from scipy.misc import imresize\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # load datasets \n",
    "    channel_model = \"VehA\"\n",
    "    SNR = 22\n",
    "    Number_of_pilots = 48\n",
    "  #  perfect = loadmat(\"Perfect_H_40000\"+ channel_model.mat)['My_perfect_H']\n",
    "    #perfect = loadmat(\"Perfect_H_40000\", appendmat = True)['My_perfect_H']\n",
    "    #noisy_input = loadmat(\"Noisy_\" + channel_model + \"_\" + \"SNR_\" + str(SNR) + \".mat\") [channel_model+\"_noisy_\"+ str(SNR)]  \n",
    "    #noisy_input = loadmat(\"My_noisy_H_22\", appendmat = True )[\"My_noisy_H\"]  \n",
    "                      \n",
    "    interp_noisy = interpolation(noisy_input , SNR , Number_of_pilots , 'rbf')\n",
    "\n",
    "    perfect_image = numpy.zeros((len(perfect),72,14,2))\n",
    "    perfect_image[:,:,:,0] = numpy.real(perfect)\n",
    "    perfect_image[:,:,:,1] = numpy.imag(perfect)\n",
    "    perfect_image = numpy.concatenate((perfect_image[:,:,:,0], perfect_image[:,:,:,1]), axis=0).reshape(2*len(perfect), 72, 14, 1)\n",
    "    \n",
    "    \n",
    "    ####### ------ training SRCNN ------ #######\n",
    "    idx_random = numpy.random.rand(len(perfect_image)) < (1/9)  # uses 32000 from 36000 as training and the rest as validation\n",
    "    train_data, train_label = interp_noisy[idx_random,:,:,:] , perfect_image[idx_random,:,:,:]\n",
    "    val_data, val_label = interp_noisy[~idx_random,:,:,:] , perfect_image[~idx_random,:,:,:]    \n",
    "    SRCNN_train(train_data ,train_label, val_data , val_label , channel_model , Number_of_pilots , SNR )\n",
    "    \n",
    "   \n",
    "    ####### ------ prediction using SRCNN ------ #######\n",
    "    srcnn_pred_train = SRCNN_predict(train_data, channel_model , Number_of_pilots , SNR)\n",
    "    srcnn_pred_validation = SRCNN_predict(val_data, channel_model , Number_of_pilots , SNR)  \n",
    "                      \n",
    "                      \n",
    "    ####### ------ training DNCNN ------ #######\n",
    "    \n",
    "    DNCNN_train(train_data ,train_label, val_data , val_label, channel_model , Number_of_pilots, SNR )\n",
    "    \n",
    "    ######--------predicting using DNCNN ----####\n",
    "    \n",
    "    DNCNN_pred = DNCNN_predict(train_data, channel_model , Number_of_pilots , SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "019229ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 72, 14, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 72, 14, 64)        5248      \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 72, 14, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 72, 14, 1)         801       \n",
      "=================================================================\n",
      "Total params: 8,129\n",
      "Trainable params: 8,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.1766 - mean_squared_error: 0.1766\n",
      "Epoch 00001: val_loss improved from inf to 0.01705, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 64s 920ms/step - loss: 0.1763 - mean_squared_error: 0.1763 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 2/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0116 - mean_squared_error: 0.0116\n",
      "Epoch 00002: val_loss improved from 0.01705 to 0.00835, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 62s 892ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0069 - mean_squared_error: 0.0069\n",
      "Epoch 00003: val_loss improved from 0.00835 to 0.00586, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 62s 891ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
      "Epoch 4/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0052 - mean_squared_error: 0.0052\n",
      "Epoch 00004: val_loss improved from 0.00586 to 0.00470, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 896ms/step - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0047 - val_mean_squared_error: 0.0047\n",
      "Epoch 5/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 00005: val_loss improved from 0.00470 to 0.00407, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 898ms/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0038 - mean_squared_error: 0.0038\n",
      "Epoch 00006: val_loss improved from 0.00407 to 0.00362, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 896ms/step - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035\n",
      "Epoch 00007: val_loss improved from 0.00362 to 0.00331, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 895ms/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 8/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 00008: val_loss improved from 0.00331 to 0.00306, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 899ms/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 9/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 00009: val_loss improved from 0.00306 to 0.00294, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 900ms/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 00010: val_loss improved from 0.00294 to 0.00272, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 900ms/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 11/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 00011: val_loss improved from 0.00272 to 0.00261, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 898ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 12/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 00012: val_loss did not improve from 0.00261\n",
      "70/70 [==============================] - 63s 895ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 13/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 00013: val_loss improved from 0.00261 to 0.00244, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 897ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 14/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 00014: val_loss improved from 0.00244 to 0.00234, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 896ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 00015: val_loss improved from 0.00234 to 0.00229, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 895ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 16/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 00016: val_loss improved from 0.00229 to 0.00225, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 62s 891ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 17/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 00017: val_loss improved from 0.00225 to 0.00218, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 893ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 18/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 00018: val_loss improved from 0.00218 to 0.00215, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 896ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 19/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 00019: val_loss improved from 0.00215 to 0.00210, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 900ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 20/20\n",
      "69/70 [============================>.] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 00020: val_loss improved from 0.00210 to 0.00205, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 63s 897ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Model: \"functional_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, None, None, 6 640         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, None, None, 6 0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, None, None, 6 36928       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, None, None, 6 256         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, None, None, 6 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, None, None, 6 36928       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, None, None, 6 256         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, None, None, 6 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, None, None, 6 36928       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, None, None, 6 256         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, None, None, 6 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, None, None, 6 36928       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, None, None, 6 256         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, None, None, 6 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, None, None, 6 36928       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, None, None, 6 256         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, None, None, 6 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, None, None, 6 36928       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, None, None, 6 256         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, None, None, 6 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, None, None, 6 36928       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, None, None, 6 256         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, None, None, 6 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, None, None, 6 36928       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, None, None, 6 256         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, None, None, 6 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, None, None, 6 36928       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, None, None, 6 256         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, None, None, 6 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, None, None, 6 36928       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, None, None, 6 256         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, None, None, 6 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, None, None, 6 36928       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, None, None, 6 256         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, None, 6 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, None, None, 6 36928       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, None, None, 6 256         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, None, 6 0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, None, None, 6 36928       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, None, None, 6 256         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, None, 6 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, None, None, 6 36928       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, None, None, 6 256         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, None, None, 6 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, None, None, 6 36928       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, None, None, 6 256         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, None, None, 6 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, None, None, 6 36928       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, None, None, 6 256         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, None, None, 6 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, None, None, 6 36928       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, None, None, 6 256         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, None, None, 6 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, None, None, 6 36928       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, None, None, 6 256         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, None, None, 6 0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, None, None, 1 577         activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract_2 (Subtract)           (None, None, None, 1 0           input_9[0][0]                    \n",
      "                                                                 conv2d_77[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 670,529\n",
      "Trainable params: 668,225\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 0.0631 - mean_squared_error: 0.0631\n",
      "Epoch 00001: val_loss improved from inf to 0.00935, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1273s 18s/step - loss: 0.0631 - mean_squared_error: 0.0631 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0044 - mean_squared_error: 0.0044\n",
      "Epoch 00002: val_loss improved from 0.00935 to 0.00888, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1289s 18s/step - loss: 0.0044 - mean_squared_error: 0.0044 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0035 - mean_squared_error: 0.0035 \n",
      "Epoch 00003: val_loss improved from 0.00888 to 0.00805, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1646s 24s/step - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0031 - mean_squared_error: 0.0031\n",
      "Epoch 00004: val_loss improved from 0.00805 to 0.00718, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1295s 19s/step - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 00005: val_loss improved from 0.00718 to 0.00640, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1294s 18s/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 00006: val_loss improved from 0.00640 to 0.00401, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1272s 18s/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 00007: val_loss improved from 0.00401 to 0.00335, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1283s 18s/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 00008: val_loss improved from 0.00335 to 0.00243, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1495s 21s/step - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0018 - mean_squared_error: 0.0018 \n",
      "Epoch 00009: val_loss did not improve from 0.00243\n",
      "70/70 [==============================] - 1504s 21s/step - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0017 - mean_squared_error: 0.0017\n",
      "Epoch 00010: val_loss improved from 0.00243 to 0.00182, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1712s 24s/step - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n"
     ]
    }
   ],
   "source": [
    "###### import numpy as np\n",
    "import numpy\n",
    "import math\n",
    "#from models import interpolation , SRCNN_train , SRCNN_model, SRCNN_predict , DNCNN_train , DNCNN_model , DNCNN_predict\n",
    "#from scipy.misc import imresize\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # load datasets \n",
    "    channel_model = \"VehA\"\n",
    "    SNR = 12\n",
    "    Number_of_pilots = 48\n",
    "  #  perfect = loadmat(\"Perfect_H_40000\"+ channel_model.mat)['My_perfect_H']\n",
    "    #perfect = loadmat(\"Perfect_H_40000\", appendmat = True)['My_perfect_H']\n",
    "    #noisy_input = loadmat(\"Noisy_\" + channel_model + \"_\" + \"SNR_\" + str(SNR) + \".mat\") [channel_model+\"_noisy_\"+ str(SNR)]  \n",
    "    #noisy_input = loadmat(\"My_noisy_H_22\", appendmat = True )[\"My_noisy_H\"]  \n",
    "                      \n",
    "    interp_noisy = interpolation(noisy_input , SNR , Number_of_pilots , 'rbf')\n",
    "\n",
    "    perfect_image = numpy.zeros((len(perfect),72,14,2))\n",
    "    perfect_image[:,:,:,0] = numpy.real(perfect)\n",
    "    perfect_image[:,:,:,1] = numpy.imag(perfect)\n",
    "    perfect_image = numpy.concatenate((perfect_image[:,:,:,0], perfect_image[:,:,:,1]), axis=0).reshape(2*len(perfect), 72, 14, 1)\n",
    "    \n",
    "    \n",
    "    ####### ------ training SRCNN ------ #######\n",
    "    idx_random = numpy.random.rand(len(perfect_image)) < (1/9)  # uses 32000 from 36000 as training and the rest as validation\n",
    "    train_data, train_label = interp_noisy[idx_random,:,:,:] , perfect_image[idx_random,:,:,:]\n",
    "    val_data, val_label = interp_noisy[~idx_random,:,:,:] , perfect_image[~idx_random,:,:,:]    \n",
    "    SRCNN_train(train_data ,train_label, val_data , val_label , channel_model , Number_of_pilots , SNR )\n",
    "    \n",
    "   \n",
    "    ####### ------ prediction using SRCNN ------ #######\n",
    "    srcnn_pred_train = SRCNN_predict(train_data, channel_model , Number_of_pilots , SNR)\n",
    "    srcnn_pred_validation = SRCNN_predict(val_data, channel_model , Number_of_pilots , SNR)  \n",
    "                      \n",
    "                      \n",
    "    ####### ------ training DNCNN ------ #######\n",
    "    \n",
    "    DNCNN_train(train_data ,train_label, val_data , val_label, channel_model , Number_of_pilots, SNR )\n",
    "    \n",
    "    ######--------predicting using DNCNN ----####\n",
    "    \n",
    "    DNCNN_pred = DNCNN_predict(train_data, channel_model , Number_of_pilots , SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "841514e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 72, 14, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 72, 14, 64)        5248      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 14, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 14, 1)         801       \n",
      "=================================================================\n",
      "Total params: 8,129\n",
      "Trainable params: 8,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0939 - mean_squared_error: 0.0939\n",
      "Epoch 00001: val_loss improved from inf to 0.01290, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 106s 2s/step - loss: 0.0939 - mean_squared_error: 0.0939 - val_loss: 0.0129 - val_mean_squared_error: 0.0129\n",
      "Epoch 2/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0089 - mean_squared_error: 0.0089\n",
      "Epoch 00002: val_loss improved from 0.01290 to 0.00620, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 113s 2s/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 3/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0051 - mean_squared_error: 0.0051\n",
      "Epoch 00003: val_loss improved from 0.00620 to 0.00438, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 116s 2s/step - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0044 - val_mean_squared_error: 0.0044\n",
      "Epoch 4/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0040 - mean_squared_error: 0.0040\n",
      "Epoch 00004: val_loss improved from 0.00438 to 0.00366, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 110s 2s/step - loss: 0.0040 - mean_squared_error: 0.0040 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "Epoch 5/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0034 - mean_squared_error: 0.0034\n",
      "Epoch 00005: val_loss improved from 0.00366 to 0.00330, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "Epoch 6/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 00006: val_loss improved from 0.00330 to 0.00316, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "Epoch 7/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0030 - mean_squared_error: 0.0030\n",
      "Epoch 00007: val_loss improved from 0.00316 to 0.00312, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "Epoch 8/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0028 - mean_squared_error: 0.0028\n",
      "Epoch 00008: val_loss improved from 0.00312 to 0.00274, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 71s 1s/step - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 9/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 00009: val_loss improved from 0.00274 to 0.00271, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 69s 988ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Epoch 10/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0026 - mean_squared_error: 0.0026\n",
      "Epoch 00010: val_loss improved from 0.00271 to 0.00259, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 68s 975ms/step - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 11/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0025 - mean_squared_error: 0.0025\n",
      "Epoch 00011: val_loss improved from 0.00259 to 0.00244, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 68s 975ms/step - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 12/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0027 - mean_squared_error: 0.0027\n",
      "Epoch 00012: val_loss did not improve from 0.00244\n",
      "70/70 [==============================] - 64s 913ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Epoch 13/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 00013: val_loss improved from 0.00244 to 0.00231, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 64s 914ms/step - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Epoch 14/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0023 - mean_squared_error: 0.0023\n",
      "Epoch 00014: val_loss improved from 0.00231 to 0.00225, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 65s 927ms/step - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 15/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 00015: val_loss improved from 0.00225 to 0.00223, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 64s 915ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 16/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 00016: val_loss did not improve from 0.00223\n",
      "70/70 [==============================] - 64s 917ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Epoch 17/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0022 - mean_squared_error: 0.0022\n",
      "Epoch 00017: val_loss improved from 0.00223 to 0.00212, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 64s 913ms/step - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 18/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 00018: val_loss improved from 0.00212 to 0.00210, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 65s 922ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 19/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 00019: val_loss improved from 0.00210 to 0.00210, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 64s 910ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 20/20\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0021 - mean_squared_error: 0.0021\n",
      "Epoch 00020: val_loss improved from 0.00210 to 0.00202, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 64s 913ms/step - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 640         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, None, 6 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 6 36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 6 256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 6 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 6 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 6 256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 6 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 6 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 6 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 6 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 6 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 6 36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 6 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 6 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 6 256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 6 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 6 36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 6 256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 6 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 6 256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 6 36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 6 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 6 36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 6 36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 6 256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 6 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 1 577         activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, None, None, 1 0           input_4[0][0]                    \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 670,529\n",
      "Trainable params: 668,225\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0709 - mean_squared_error: 0.0709\n",
      "Epoch 00001: val_loss improved from inf to 0.01229, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1266s 18s/step - loss: 0.0709 - mean_squared_error: 0.0709 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0041 - mean_squared_error: 0.0041\n",
      "Epoch 00002: val_loss improved from 0.01229 to 0.00899, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1267s 18s/step - loss: 0.0041 - mean_squared_error: 0.0041 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0033 - mean_squared_error: 0.0033\n",
      "Epoch 00003: val_loss improved from 0.00899 to 0.00831, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1297s 19s/step - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0029 - mean_squared_error: 0.0029"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-9f400cd4ff38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m####### ------ training DNCNN ------ #######\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mDNCNN_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mval_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_model\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mNumber_of_pilots\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSNR\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m######--------predicting using DNCNN ----####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-d0057ca95c0d>\u001b[0m in \u001b[0;36mDNCNN_train\u001b[1;34m(train_data, train_label, val_data, val_label, channel_model, num_pilots, SNR)\u001b[0m\n\u001b[0;32m    149\u001b[0m   \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m   dncnn_model.fit(train_data, train_label, batch_size=128, validation_data=(val_data, val_label),\n\u001b[0m\u001b[0;32m    152\u001b[0m                   callbacks=callbacks_list, shuffle=True, epochs= 10 , verbose=1)\n\u001b[0;32m    153\u001b[0m   \u001b[0mdncnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DNCNN_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mchannel_model\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_pilots\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSNR\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1121\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1123\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1124\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraceContext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    812\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###### import numpy as np\n",
    "import numpy\n",
    "import math\n",
    "#from models import interpolation , SRCNN_train , SRCNN_model, SRCNN_predict , DNCNN_train , DNCNN_model , DNCNN_predict\n",
    "#from scipy.misc import imresize\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # load datasets \n",
    "    channel_model = \"VehA\"\n",
    "    SNR = 25\n",
    "    Number_of_pilots = 48\n",
    "  #  perfect = loadmat(\"Perfect_H_40000\"+ channel_model.mat)['My_perfect_H']\n",
    "    #perfect = loadmat(\"Perfect_H_40000\", appendmat = True)['My_perfect_H']\n",
    "    #noisy_input = loadmat(\"Noisy_\" + channel_model + \"_\" + \"SNR_\" + str(SNR) + \".mat\") [channel_model+\"_noisy_\"+ str(SNR)]  \n",
    "    #noisy_input = loadmat(\"My_noisy_H_22\", appendmat = True )[\"My_noisy_H\"]  \n",
    "                      \n",
    "    interp_noisy = interpolation(noisy_input , SNR , Number_of_pilots , 'rbf')\n",
    "\n",
    "    perfect_image = numpy.zeros((len(perfect),72,14,2))\n",
    "    perfect_image[:,:,:,0] = numpy.real(perfect)\n",
    "    perfect_image[:,:,:,1] = numpy.imag(perfect)\n",
    "    perfect_image = numpy.concatenate((perfect_image[:,:,:,0], perfect_image[:,:,:,1]), axis=0).reshape(2*len(perfect), 72, 14, 1)\n",
    "    \n",
    "    \n",
    "    ####### ------ training SRCNN ------ #######\n",
    "    idx_random = numpy.random.rand(len(perfect_image)) < (1/9)  # uses 32000 from 36000 as training and the rest as validation\n",
    "    train_data, train_label = interp_noisy[idx_random,:,:,:] , perfect_image[idx_random,:,:,:]\n",
    "    val_data, val_label = interp_noisy[~idx_random,:,:,:] , perfect_image[~idx_random,:,:,:]    \n",
    "    SRCNN_train(train_data ,train_label, val_data , val_label , channel_model , Number_of_pilots , SNR )\n",
    "    \n",
    "   \n",
    "    ####### ------ prediction using SRCNN ------ #######\n",
    "    srcnn_pred_train = SRCNN_predict(train_data, channel_model , Number_of_pilots , SNR)\n",
    "    srcnn_pred_validation = SRCNN_predict(val_data, channel_model , Number_of_pilots , SNR)  \n",
    "                      \n",
    "                      \n",
    "    ####### ------ training DNCNN ------ #######\n",
    "    \n",
    "    DNCNN_train(train_data ,train_label, val_data , val_label, channel_model , Number_of_pilots, SNR )\n",
    "    \n",
    "    ######--------predicting using DNCNN ----####\n",
    "    \n",
    "    DNCNN_pred = DNCNN_predict(train_data, channel_model , Number_of_pilots , SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfbe1216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 72, 14, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 72, 14, 64)        5248      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 14, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 14, 1)         801       \n",
      "=================================================================\n",
      "Total params: 8,129\n",
      "Trainable params: 8,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0693 - mean_squared_error: 0.0693\n",
      "Epoch 00001: val_loss improved from inf to 0.03179, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 99s 1s/step - loss: 0.0693 - mean_squared_error: 0.0693 - val_loss: 0.0318 - val_mean_squared_error: 0.0318\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0292 - mean_squared_error: 0.0292\n",
      "Epoch 00002: val_loss improved from 0.03179 to 0.02702, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0270 - val_mean_squared_error: 0.0270\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0259 - mean_squared_error: 0.0259\n",
      "Epoch 00003: val_loss improved from 0.02702 to 0.02473, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.0259 - mean_squared_error: 0.0259 - val_loss: 0.0247 - val_mean_squared_error: 0.0247\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0243 - mean_squared_error: 0.0243\n",
      "Epoch 00004: val_loss improved from 0.02473 to 0.02356, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0234 - mean_squared_error: 0.0234\n",
      "Epoch 00005: val_loss improved from 0.02356 to 0.02308, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0231 - val_mean_squared_error: 0.0231\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0227 - mean_squared_error: 0.0227\n",
      "Epoch 00006: val_loss improved from 0.02308 to 0.02231, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 97s 1s/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0223 - val_mean_squared_error: 0.0223\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0224 - mean_squared_error: 0.0224\n",
      "Epoch 00007: val_loss improved from 0.02231 to 0.02209, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0219 - mean_squared_error: 0.0219\n",
      "Epoch 00008: val_loss improved from 0.02209 to 0.02163, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0217 - mean_squared_error: 0.0217\n",
      "Epoch 00009: val_loss improved from 0.02163 to 0.02151, saving model to SRCNN_check.h5\n",
      "70/70 [==============================] - 98s 1s/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0215 - mean_squared_error: 0.0215\n",
      "Epoch 00010: val_loss did not improve from 0.02151\n",
      "70/70 [==============================] - 96s 1s/step - loss: 0.0215 - mean_squared_error: 0.0215 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, None, None, 6 640         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, None, 6 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, None, None, 6 36928       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, None, 6 256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, None, 6 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, None, None, 6 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, None, 6 256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, None, 6 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, None, None, 6 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, None, 6 256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, None, None, 6 36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, None, 6 256         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, None, None, 6 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, None, None, 6 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, None, 6 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, None, None, 6 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, None, None, 6 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, None, None, 6 36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, None, None, 6 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, None, None, 6 36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, None, None, 6 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, None, None, 6 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, None, None, 6 256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 6 36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, None, None, 6 256         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 6 36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, None, None, 6 256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, None, 6 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 6 36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, None, None, 6 256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, None, 6 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, None, None, 6 256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 6 36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, None, None, 6 256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 6 36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, None, None, 6 256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, None, None, 6 36928       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, None, None, 6 256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, None, None, 6 36928       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, None, None, 6 256         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, None, None, 6 36928       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, None, None, 6 256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, None, 6 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, None, None, 1 577         activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "subtract (Subtract)             (None, None, None, 1 0           input_4[0][0]                    \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 670,529\n",
      "Trainable params: 668,225\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 0.1500 - mean_squared_error: 0.1500\n",
      "Epoch 00001: val_loss improved from inf to 0.17461, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1471s 21s/step - loss: 0.1500 - mean_squared_error: 0.1500 - val_loss: 0.1746 - val_mean_squared_error: 0.1746\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0250 - mean_squared_error: 0.0250\n",
      "Epoch 00002: val_loss improved from 0.17461 to 0.15561, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1415s 20s/step - loss: 0.0250 - mean_squared_error: 0.0250 - val_loss: 0.1556 - val_mean_squared_error: 0.1556\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0235 - mean_squared_error: 0.0235\n",
      "Epoch 00003: val_loss improved from 0.15561 to 0.13532, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 1936s 28s/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.1353 - val_mean_squared_error: 0.1353\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0227 - mean_squared_error: 0.0227 \n",
      "Epoch 00004: val_loss improved from 0.13532 to 0.11371, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 2555s 36s/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.1137 - val_mean_squared_error: 0.1137\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0225 - mean_squared_error: 0.0225 \n",
      "Epoch 00005: val_loss improved from 0.11371 to 0.08444, saving model to DNCNN_check.h5\n",
      "70/70 [==============================] - 2518s 36s/step - loss: 0.0225 - mean_squared_error: 0.0225 - val_loss: 0.0844 - val_mean_squared_error: 0.0844\n"
     ]
    }
   ],
   "source": [
    "###### import numpy as np\n",
    "import numpy\n",
    "import math\n",
    "#from models import interpolation , SRCNN_train , SRCNN_model, SRCNN_predict , DNCNN_train , DNCNN_model , DNCNN_predict\n",
    "#from scipy.misc import imresize\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # load datasets \n",
    "    channel_model = \"VehA\"\n",
    "    SNR = 20\n",
    "    Number_of_pilots = 8\n",
    "  #  perfect = loadmat(\"Perfect_H_40000\"+ channel_model.mat)['My_perfect_H']\n",
    "    #perfect = loadmat(\"Perfect_H_40000\", appendmat = True)['My_perfect_H']\n",
    "    #noisy_input = loadmat(\"Noisy_\" + channel_model + \"_\" + \"SNR_\" + str(SNR) + \".mat\") [channel_model+\"_noisy_\"+ str(SNR)]  \n",
    "    #noisy_input = loadmat(\"My_noisy_H_22\", appendmat = True )[\"My_noisy_H\"]  \n",
    "                      \n",
    "    interp_noisy = interpolation(noisy_input , SNR , Number_of_pilots , 'rbf')\n",
    "\n",
    "    perfect_image = numpy.zeros((len(perfect),72,14,2))\n",
    "    perfect_image[:,:,:,0] = numpy.real(perfect)\n",
    "    perfect_image[:,:,:,1] = numpy.imag(perfect)\n",
    "    perfect_image = numpy.concatenate((perfect_image[:,:,:,0], perfect_image[:,:,:,1]), axis=0).reshape(2*len(perfect), 72, 14, 1)\n",
    "    \n",
    "    \n",
    "    ####### ------ training SRCNN ------ #######\n",
    "    idx_random = numpy.random.rand(len(perfect_image)) < (1/9)  # uses 32000 from 36000 as training and the rest as validation\n",
    "    train_data, train_label = interp_noisy[idx_random,:,:,:] , perfect_image[idx_random,:,:,:]\n",
    "    val_data, val_label = interp_noisy[~idx_random,:,:,:] , perfect_image[~idx_random,:,:,:]    \n",
    "    SRCNN_train(train_data ,train_label, val_data , val_label , channel_model , Number_of_pilots , SNR )\n",
    "    \n",
    "   \n",
    "    ####### ------ prediction using SRCNN ------ #######\n",
    "    srcnn_pred_train = SRCNN_predict(train_data, channel_model , Number_of_pilots , SNR)\n",
    "    srcnn_pred_validation = SRCNN_predict(val_data, channel_model , Number_of_pilots , SNR)  \n",
    "                      \n",
    "                      \n",
    "    ####### ------ training DNCNN ------ #######\n",
    "    \n",
    "    DNCNN_train(train_data ,train_label, val_data , val_label, channel_model , Number_of_pilots, SNR )\n",
    "    \n",
    "    ######--------predicting using DNCNN ----####\n",
    "    \n",
    "    DNCNN_pred = DNCNN_predict(train_data, channel_model , Number_of_pilots , SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74635e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
